<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="fIqzv9P1o2QLMhccsI2bnCnEezMQBfoOcogi-zeZP7Q"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Patrick (Pengcheng) Jiang</title> <meta name="author" content="Patrick (Pengcheng) Jiang"> <meta name="description" content=""> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/jiang.png"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pat-jj.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> <meta name="google-site-verification" content="fIqzv9P1o2QLMhccsI2bnCnEezMQBfoOcogi-zeZP7Q"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Patrick </span>(Pengcheng) Jiang</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/software/">software</a> </li> <li class="nav-item "> <a class="nav-link" target="_blank" href="/assets/pdf/CV.pdf">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Preprint</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/graphcare-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/graphcare-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/graphcare-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/graphcare-1400.webp"></source> <img src="/assets/img/publication_preview/graphcare.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="graphcare.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="jiang2023graphcare" class="col-sm-8"> <div class="title">GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs</div> <div class="author"> <strong><ins style="color:rgb(181, 50, 251); font-weight: bold;">Pengcheng Jiang</ins></strong>, <a href="https://sites.google.com/view/danicaxiao/home?pli=1" rel="external nofollow noopener" target="_blank">Cao Xiao</a>, <a href="https://www2.osfhealthcare.org/providers/adam-cross-1601889" rel="external nofollow noopener" target="_blank">Adam Cross</a>, and <a href="https://www.sunlab.org/" rel="external nofollow noopener" target="_blank">Jimeng Sun</a> </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/graphcare.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/pat-jj/GraphCare" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <span id="star-count-jiang2023graphcare" class="github-stars"></span> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Clinical predictive models often rely on patients’ electronic health records (EHR), but integrating medical knowledge to enhance predictions and decision-making is challenging. This is because personalized predictions require personalized knowledge graphs (KGs), which are difficult to generate from patient EHR data. To address this, we propose GRAPHCARE, an open-world framework that uses external KGs to improve EHR-based predictions. Our method extracts knowledge from large language models (LLMs) and external biomedical KGs to build patientspecific KGs, which are then used to train our proposed Bi-attention AugmenTed (BAT) graph neural network (GNN) for healthcare predictions. On two public datasets, MIMIC-III and MIMIC-IV, GRAPHCARE surpasses baselines in four vital healthcare prediction tasks: mortality, readmission, length of stay (LOS), and drug recommendation. On MIMIC-III, it boosts AUROC by 17.6% and 6.6% for mortality and readmission, and F1-score by 7.9% and 10.8% for LOS and drug recommendation, respectively. Notably, GRAPHCARE demonstrates a substantial edge in scenarios with limited data availability. Our findings highlight the potential of using external KGs in healthcare prediction tasks and demonstrate the promise of GRAPHCARE in generating personalized KGs for promoting personalized medicine.</p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#f68e52;padding:3px;color:#140022;border-radius:5px;margin-left:-10px;margin-top:3px}</style> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Preprint</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/gode-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/gode-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/gode-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/gode-1400.webp"></source> <img src="/assets/img/publication_preview/gode.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="gode.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="jiang2023bilevel" class="col-sm-8"> <div class="title">Bi-level Contrastive Learning for Knowledge-Enhanced Molecule Representations</div> <div class="author"> <strong><ins style="color:rgb(181, 50, 251); font-weight: bold;">Pengcheng Jiang</ins></strong>, <a href="https://sites.google.com/view/danicaxiao/home?pli=1" rel="external nofollow noopener" target="_blank">Cao Xiao</a>, <a href="https://futianfan.github.io/" rel="external nofollow noopener" target="_blank">Tianfan Fu</a>, and <a href="https://www.sunlab.org/" rel="external nofollow noopener" target="_blank">Jimeng Sun</a> </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/gode.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/pat-jj/Gode" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <span id="star-count-jiang2023bilevel" class="github-stars"></span> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Molecule representation learning underpins diverse downstream applications such as molecular property and side effect understanding and prediction. In this paper, we recognize the two-level structure of individual molecule as having intrinsic graph structure as well as being a node in a large molecule knowledge graph, and present GODE, a new approach that seamlessly integrates graph representations of individual molecules with multi-domain biomedical data from knowledge graphs. By pre-training two graph neural networks (GNNs) on different graph structures, combined with contrastive learning, GODE adeptly fuses molecular structures with their corresponding knowledge graph substructures. This fusion results in a more robust and informative representation, enhancing molecular property prediction by harnessing both chemical and biological information. Finetuned on 11 chemical property tasks, our model surpasses benchmarks, achieving an average ROC-AUC improvement of 14.5%, 9.8%, and 7.3% on BBBP, SIDER, and Tox21 datasets. In regression tasks on ESOL and QM7 datasets, we achieve average improvements of 21.0% and 29.6% improvements in RMSE and MAE, setting a new field benchmark.</p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#f68e52;padding:3px;color:#140022;border-radius:5px;margin-left:-10px;margin-top:3px}</style> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Preprint</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/trisum-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/trisum-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/trisum-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/trisum-1400.webp"></source> <img src="/assets/img/publication_preview/trisum.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="trisum.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="jiang2023trisum" class="col-sm-8"> <div class="title">TriSum: Learning Summarization Ability from Large Language Models</div> <div class="author"> <strong><ins style="color:rgb(181, 50, 251); font-weight: bold;">Pengcheng Jiang</ins></strong>, <a href="https://sites.google.com/view/danicaxiao/home?pli=1" rel="external nofollow noopener" target="_blank">Cao Xiao</a>, <a href="https://zifengwang.xyz/" rel="external nofollow noopener" target="_blank">Zifeng Wang</a>, <a href="https://www.sunlab.org/" rel="external nofollow noopener" target="_blank">Jimeng Sun</a>, and <a href="http://hanj.cs.illinois.edu/" rel="external nofollow noopener" target="_blank">Jiawei Han</a> </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/trisum.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/pat-jj/TriSum" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>The advent of large language models (LLMs) greatly advanced natural language processing tasks, such as text summarization. However, due to their substantial model size, computational demands, and potential pri- vacy concerns when transmitting sensitive data for re- mote processing, their utility can be limited in resource- constrained environments and applications prioritizing data privacy. To address this, we introduce a frame- work called TriSum to distill the text summarization capabilities of LLMs into a more compact local model. In the first step, we employ LLMs to probe and ex- tract a collection of aspect-triple rationales and sum- maries. We then refine them by employing a dual- scoring method to identify the most high-quality ratio- nales. Moving to the second step, we train a smaller lo- cal model using these carefully organized summariza- tion tasks. Our training strategy employs a curriculum learning approach, gradually progressing from individ- ual tasks to more complex combinations. Our evalua- tions demonstrate that our TriSum method empowers the local model to outperform baselines by 4.5%, 8.5%, and 7.4% for the abstractive summarization task on CN- N/DailyMail, XSum, and ClinicalTrial respectively. Be- yond improved performance, our approach also offers insights into the rationale guiding the summarization process, thus enhancing interpretability.</p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#f68e52;padding:3px;color:#140022;border-radius:5px;margin-left:-10px;margin-top:3px}</style> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">KDD’23</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/pyhealth-logo-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/pyhealth-logo-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/pyhealth-logo-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/pyhealth-logo-1400.webp"></source> <img src="/assets/img/publication_preview/pyhealth-logo.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="pyhealth-logo.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="10.1145/3580305.3599178" class="col-sm-8"> <div class="title">PyHealth: A Deep Learning Toolkit for Healthcare Applications</div> <div class="author"> <a href="https://ycq091044.github.io/" rel="external nofollow noopener" target="_blank">Chaoqi Yang</a>, <a href="https://zzachw.github.io/" rel="external nofollow noopener" target="_blank">Zhenbang Wu</a>, <strong><ins style="color:rgb(181, 50, 251); font-weight: bold;">Patrick Jiang</ins></strong>, <a href="https://zlin7.github.io/" rel="external nofollow noopener" target="_blank">Zhen Lin</a>, <a href="http://aboutme.vixerunt.org/" rel="external nofollow noopener" target="_blank">Junyi Gao</a>, <a href="https://www.linkedin.com/in/benjaminpdanek/" rel="external nofollow noopener" target="_blank">Benjamin Danek</a>, and <a href="https://www.sunlab.org/" rel="external nofollow noopener" target="_blank">Jimeng Sun</a> </div> <div class="periodical"> <em>In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/pyhealth.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/sunlabuiuc/PyHealth" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <span id="star-count-10.1145/3580305.3599178" class="github-stars"></span> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Deep learning (DL) has emerged as a promising tool in healthcare applications. However, the reproducibility of many studies in this field is limited by the lack of accessible code implementations and standard benchmarks. To address the issue, we create PyHealth, a comprehensive library to build, deploy, and validate DL pipelines for healthcare applications. PyHealth supports various data modalities, including electronic health records (EHRs), physiological signals, medical images, and clinical text. It offers various advanced DL models and maintains comprehensive medical knowledge systems. The library is designed to support both DL researchers and clinical data scientists. Upon the time of writing, PyHealth has received 633 stars, 130 forks, and 15k+ downloads in total on GitHub.This tutorial will provide an overview of PyHealth, present different modules, and showcase their functionality through hands-on demos. Participants can follow along and gain hands-on experience on the Google Colab platform during the session.</p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#f68e52;padding:3px;color:#140022;border-radius:5px;margin-left:-10px;margin-top:3px}</style> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ACL’23</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/tagreal-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/tagreal-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/tagreal-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/tagreal-1400.webp"></source> <img src="/assets/img/publication_preview/tagreal.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="tagreal.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="jiang-etal-2023-text" class="col-sm-8"> <div class="title">Text Augmented Open Knowledge Graph Completion via Pre-Trained Language Models</div> <div class="author"> <strong><ins style="color:rgb(181, 50, 251); font-weight: bold;">Pengcheng Jiang</ins></strong>, <a href="https://shivamag125.github.io/" rel="external nofollow noopener" target="_blank">Shivam Agarwal</a>, <a href="https://peterjin.me/" rel="external nofollow noopener" target="_blank">Bowen Jin</a>, <a href="https://xuanwang91.github.io/" rel="external nofollow noopener" target="_blank">Xuan Wang</a>, <a href="https://www.sunlab.org/" rel="external nofollow noopener" target="_blank">Jimeng Sun</a>, and <a href="http://hanj.cs.illinois.edu/" rel="external nofollow noopener" target="_blank">Jiawei Han</a> </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: ACL 2023</em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/tagreal.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/tagreal_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> <a href="https://github.com/pat-jj/TagReal" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <span id="star-count-jiang-etal-2023-text" class="github-stars"></span> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>The mission of open knowledge graph (KG) completion is to draw new findings from known facts. Existing works that augment KG completion require either (1) factual triples to enlarge the graph reasoning space or (2) manually designed prompts to extract knowledge from a pre-trained language model (PLM), exhibiting limited performance and requiring expensive efforts from experts. To this end, we propose TagReal that automatically generates quality query prompts and retrieves support information from large text corpora to probe knowledge from PLM for KG completion. The results show that TagReal achieves state-of-the-art performance on two benchmark datasets. We find that TagReal has superb performance even with limited training data, outperforming existing embedding-based, graph-based, and PLM-based methods.</p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#f68e52;padding:3px;color:#140022;border-radius:5px;margin-left:-10px;margin-top:3px}</style> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">IEEE AINIT</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/skin-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/skin-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/skin-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/skin-1400.webp"></source> <img src="/assets/img/publication_preview/skin.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="skin.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="9725092" class="col-sm-8"> <div class="title">CNN-based Diagnosis System on Skin Cancer using Ensemble Method Weighted by Cubic Precision</div> <div class="author"> <strong><ins style="color:rgb(181, 50, 251); font-weight: bold;">Pengcheng Jiang</ins></strong> </div> <div class="periodical"> <em>In 2021 2nd International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)</em>, Aug 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/skin_vision.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/pat-jj/skin_cancer_vision" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>One of the most prevalent diseases, skin cancer, has been proven to be treatable at an early stage. Thus, techniques that allow individuals to identify skin cancer symptoms early are in great demand. This paper proposed an interactive skin lesion diagnosis system based on the ensemble of multiple sophisticated CNN models for image classification. The performance of ResNet50, ResNeXt50, ResNeXt101, EfficientNetB4, Mobile-NetV2, MobileNetV3, and MnasNet are investigated separately as ensemble components. Then, using various criteria, we constructed ensembles and compared the accuracy they achieved. Moreover, we designed a method to update the ensemble for new data and examined its performance. In addition, a few natural language processing (NLP) techniques were used to make our system more user-friendly. To integrate all the functionalities, we built a user interface with PyQt5. As a result, MobileNetV3 achieved 91.02% as the best accuracy among all single models; ensemble weighted by cubic precision achieved 92.84% accuracy as the highest one in this study; a notable improvement in accuracy demonstrated the effectiveness of the model updating approach, and a system with all of the desired features was successfully developed. These findings benefit in two aspects. For model performance, applying cubic precisions can increase ensemble learning classification accuracy. For the developed diagnosis system, it can aid in the early detection of the skin lesions for skin cancer treatment.</p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#f68e52;padding:3px;color:#140022;border-radius:5px;margin-left:-10px;margin-top:3px}</style> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">IEEE SSCI</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/oacal-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/oacal-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/oacal-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/oacal-1400.webp"></source> <img src="/assets/img/publication_preview/oacal.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="oacal.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="9660106" class="col-sm-8"> <div class="title">OACAL: Finding Module-consistent Specifications to Secure Systems from Weakened User Obligations</div> <div class="author"> <strong><ins style="color:rgb(181, 50, 251); font-weight: bold;">Pengcheng Jiang</ins></strong>, and <a href="https://www.tei-lab.jp/en/professors/" rel="external nofollow noopener" target="_blank">Kenji Tei</a> </div> <div class="periodical"> <em>In 2021 IEEE Symposium Series on Computational Intelligence (SSCI)</em>, Jul 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/oacal.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/oacal_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> <a href="https://github.com/pat-jj/OACAL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Users interacting with a system through UI are typically obliged to perform their actions in a pre-determined order, to successfully achieve certain functional goals. However, such obligations are often not followed strictly by users, which may lead to the violation to security properties, especially in security-critical systems. To improve the security with the awareness of unexpected user behaviors, a system can be redesigned to a more robust one by changing the order of actions in its specification. Meanwhile, we anticipate that the functionalities would remain consistent following the modifications. In this paper, we propose an efficient algorithm to automatically produce specification revisions tackling the attack scenarios caused by weakened user obligations. By our algorithm, all the revisions would be generated to maintain the integrity of the functionalities using a novel recomposition approach. Then, the eligible revisions that can satisfy the security requirements would be efficiently spotted by a hybrid approach combining model checking and machine learning techniques. We evaluate our algorithm by comparing its performance with a state-of-the-art approach regarding their coverage and searching speed of the desirable revisions.</p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#f68e52;padding:3px;color:#140022;border-radius:5px;margin-left:-10px;margin-top:3px}</style> </li> </ol> </div> </article> </div> <div id="clustrmaps-container" style="width: 110px; height: 110px;"> <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=bWiKAH2bSIjAc4dLQ15AfqQN92lAkCtT2Bc8n2ovxw8"></script> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Patrick (Pengcheng) Jiang. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>