<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="fIqzv9P1o2QLMhccsI2bnCnEezMQBfoOcogi-zeZP7Q"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Patrick (Pengcheng) Jiang</title> <meta name="author" content="Patrick (Pengcheng) Jiang"> <meta name="description" content=""> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/jiang.png"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pat-jj.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/monokai.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> <meta name="google-site-verification" content="fIqzv9P1o2QLMhccsI2bnCnEezMQBfoOcogi-zeZP7Q"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/software/">software</a> </li> <li class="nav-item "> <a class="nav-link" target="_blank" href="/assets/pdf/CV.pdf">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Patrick</span> (Pengcheng) Jiang </h1> <p class="desc"><a href="https://cs.illinois.edu/academics/graduate/ms-program" rel="external nofollow noopener" target="_blank">MSCS</a> @ <a href="https://cs.illinois.edu/" rel="external nofollow noopener" target="_blank">UIUC</a>.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/prof_pic-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg?b96ab9fa4bdf93fb11f9a93c50bfbc42" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p>Hello and welcome! I’m Patrick (Pengcheng), currently a graduate student in the Computer Science Department at the University of Illinois Urbana-Champaign (UIUC).</p> <p>I am fortunate to be advised by <a href="https://www.sunlab.org/" rel="external nofollow noopener" target="_blank">Prof. Jimeng Sun</a>, whose insights have been pivotal in shaping my research at the intersection of AI and Healthcare.</p> <p>I am also privileged to be advised by <a href="http://hanj.cs.illinois.edu/" rel="external nofollow noopener" target="_blank">Prof. Jiawei Han</a> for text mining related research, with a special focus on pre-trained language model and knowledge graph (KG).</p> <p>Prior to my studies at UIUC, I earned my B.E. in Computer Science and Engineering from Waseda University in Tokyo, Japan. In this chapter of my academic journey, I was fortunate to be co-advised by <a href="https://www.tei-lab.jp/en/professors/" rel="external nofollow noopener" target="_blank">Prof. Kenji Tei</a> and <a href="https://www.nii.ac.jp/en/faculty/architecture/honiden_shinichi/" rel="external nofollow noopener" target="_blank">Prof. Shinichi Honiden</a>, focusing on formal methods. After Waseda and before UIUC, I dedicated a year in industry as a software engineer.</p> <p>I have a wide array of research interests that span across various domains.</p> <p>My recent research is mainly about:</p> <ul> <li> <strong>Knowledge Extraction:</strong> <ul> <li>How to extract knowledge from unstructured data more efficiently and effectively?</li> <li>How to evaluate the quality of extracted knowledge?</li> </ul> </li> <li> <strong>Knowledge-Enhanced AI4Health:</strong> <ul> <li>Using KGs to improve clinical predictions.</li> <li>Using KGs to enhance molecule representation.</li> </ul> </li> </ul> <div class="language-R highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">I</span><span class="w"> </span><span class="n">am</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">discussions</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">any</span><span class="w"> </span><span class="n">promising</span><span class="w"> </span><span class="n">research</span><span class="w"> </span><span class="n">topics</span><span class="p">,</span><span class="w"> </span><span class="n">especially</span><span class="w"> </span><span class="n">those</span><span class="w"> </span><span class="n">related</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">drug</span><span class="w"> </span><span class="n">discovery.</span><span class="w">
</span><span class="n">Feel</span><span class="w"> </span><span class="n">free</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">reach</span><span class="w"> </span><span class="n">out</span><span class="o">:</span><span class="w"> </span><span class="n">pj20</span><span class="p">[</span><span class="n">at</span><span class="p">]</span><span class="n">illinois</span><span class="p">[</span><span class="n">dot</span><span class="p">]</span><span class="n">edu</span><span class="w">
</span></code></pre></div></div> </div> <h2 style="margin-top: 80px;"><a href="/publications/" style="color: inherit;"><strong>Research Experience</strong></a></h2> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICLR’24</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/graphcare-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/graphcare-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/graphcare-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/graphcare-1400.webp"></source> <img src="/assets/img/publication_preview/graphcare.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="graphcare.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="jiang2023graphcare" class="col-sm-8"> <div class="title">GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs</div> <div class="author"> <strong><ins style="color:rgb(6, 130, 213); font-weight: bold;">Pengcheng Jiang</ins></strong>, <a href="https://sites.google.com/view/danicaxiao/home?pli=1" rel="external nofollow noopener" target="_blank">Cao Xiao</a>, <a href="https://www2.osfhealthcare.org/providers/adam-cross-1601889" rel="external nofollow noopener" target="_blank">Adam Cross</a>, and <a href="https://www.sunlab.org/" rel="external nofollow noopener" target="_blank">Jimeng Sun</a> </div> <div class="periodical"> <em>In The Twelfth International Conference on Learning Representations</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/graphcare.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/pat-jj/GraphCare" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <span id="star-count-jiang2023graphcare" class="github-stars"></span> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Clinical predictive models often rely on patients’ electronic health records (EHR), but integrating medical knowledge to enhance predictions and decision-making is challenging. This is because personalized predictions require personalized knowledge graphs (KGs), which are difficult to generate from patient EHR data. To address this, we propose GRAPHCARE, an open-world framework that uses external KGs to improve EHR-based predictions. Our method extracts knowledge from large language models (LLMs) and external biomedical KGs to build patientspecific KGs, which are then used to train our proposed Bi-attention AugmenTed (BAT) graph neural network (GNN) for healthcare predictions. On two public datasets, MIMIC-III and MIMIC-IV, GRAPHCARE surpasses baselines in four vital healthcare prediction tasks: mortality, readmission, length of stay (LOS), and drug recommendation. On MIMIC-III, it boosts AUROC by 17.6% and 6.6% for mortality and readmission, and F1-score by 7.9% and 10.8% for LOS and drug recommendation, respectively. Notably, GRAPHCARE demonstrates a substantial edge in scenarios with limited data availability. Our findings highlight the potential of using external KGs in healthcare prediction tasks and demonstrate the promise of GRAPHCARE in generating personalized KGs for promoting personalized medicine.</p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal",jiang2023medkg:"pat-jj/TextbookKG",jiang2023genres:"pat-jj/GenRES"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#ddeceb;padding:3px;color:#000;border-radius:5px;margin-left:-8px;height:auto}</style> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Under Review</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/gode-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/gode-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/gode-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/gode-1400.webp"></source> <img src="/assets/img/publication_preview/gode.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="gode.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="jiang2023bilevel" class="col-sm-8"> <div class="title">Bi-level Contrastive Learning for Knowledge-Enhanced Molecule Representations</div> <div class="author"> <strong><ins style="color:rgb(6, 130, 213); font-weight: bold;">Pengcheng Jiang</ins></strong>, <a href="https://sites.google.com/view/danicaxiao/home?pli=1" rel="external nofollow noopener" target="_blank">Cao Xiao</a>, <a href="https://futianfan.github.io/" rel="external nofollow noopener" target="_blank">Tianfan Fu</a>, and <a href="https://www.sunlab.org/" rel="external nofollow noopener" target="_blank">Jimeng Sun</a> </div> <div class="periodical"> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/gode.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/pat-jj/Gode" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <span id="star-count-jiang2023bilevel" class="github-stars"></span> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Molecule representation learning underpins diverse downstream applications such as molecular property and side effect understanding and prediction. In this paper, we recognize the two-level structure of individual molecule as having intrinsic graph structure as well as being a node in a large molecule knowledge graph, and present GODE, a new approach that seamlessly integrates graph representations of individual molecules with multi-domain biomedical data from knowledge graphs. By pre-training two graph neural networks (GNNs) on different graph structures, combined with contrastive learning, GODE adeptly fuses molecular structures with their corresponding knowledge graph substructures. This fusion results in a more robust and informative representation, enhancing molecular property prediction by harnessing both chemical and biological information. Finetuned on 11 chemical property tasks, our model surpasses benchmarks, achieving an average ROC-AUC improvement of 14.5%, 9.8%, and 7.3% on BBBP, SIDER, and Tox21 datasets. In regression tasks on ESOL and QM7 datasets, we achieve average improvements of 21.0% and 29.6% improvements in RMSE and MAE, setting a new field benchmark.</p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal",jiang2023medkg:"pat-jj/TextbookKG",jiang2023genres:"pat-jj/GenRES"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#ddeceb;padding:3px;color:#000;border-radius:5px;margin-left:-8px;height:auto}</style> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NAACL’24</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/trisum-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/trisum-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/trisum-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/trisum-1400.webp"></source> <img src="/assets/img/publication_preview/trisum.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="trisum.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="jiang2023trisum" class="col-sm-8"> <div class="title">TriSum: Learning Summarization Ability from Large Language Models</div> <div class="author"> <strong><ins style="color:rgb(6, 130, 213); font-weight: bold;">Pengcheng Jiang</ins></strong>, <a href="https://sites.google.com/view/danicaxiao/home?pli=1" rel="external nofollow noopener" target="_blank">Cao Xiao</a>, <a href="https://zifengwang.xyz/" rel="external nofollow noopener" target="_blank">Zifeng Wang</a>, <a href="https://www.sunlab.org/" rel="external nofollow noopener" target="_blank">Jimeng Sun</a>, and <a href="http://hanj.cs.illinois.edu/" rel="external nofollow noopener" target="_blank">Jiawei Han</a> </div> <div class="periodical"> <em>In Proc. 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/trisum-naacl.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/pat-jj/TriSum" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>The advent of large language models (LLMs) greatly advanced natural language processing tasks, such as text summarization. However, due to their substantial model size, computational demands, and potential pri- vacy concerns when transmitting sensitive data for re- mote processing, their utility can be limited in resource- constrained environments and applications prioritizing data privacy. To address this, we introduce a frame- work called TriSum to distill the text summarization capabilities of LLMs into a more compact local model. In the first step, we employ LLMs to probe and ex- tract a collection of aspect-triple rationales and sum- maries. We then refine them by employing a dual- scoring method to identify the most high-quality ratio- nales. Moving to the second step, we train a smaller lo- cal model using these carefully organized summariza- tion tasks. Our training strategy employs a curriculum learning approach, gradually progressing from individ- ual tasks to more complex combinations. Our evalua- tions demonstrate that our TriSum method empowers the local model to outperform baselines by 4.5%, 8.5%, and 7.4% for the abstractive summarization task on CN- N/DailyMail, XSum, and ClinicalTrial respectively. Be- yond improved performance, our approach also offers insights into the rationale guiding the summarization process, thus enhancing interpretability.</p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal",jiang2023medkg:"pat-jj/TextbookKG",jiang2023genres:"pat-jj/GenRES"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#ddeceb;padding:3px;color:#000;border-radius:5px;margin-left:-8px;height:auto}</style> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NAACL’24</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/genres-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/genres-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/genres-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/genres-1400.webp"></source> <img src="/assets/img/publication_preview/genres.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="genres.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="jiang2023genres" class="col-sm-8"> <div class="title">GenRES: Rethinking Evaluation for Generative Relation Extraction in the Era of Large Language Models</div> <div class="author"> <strong><ins style="color:rgb(6, 130, 213); font-weight: bold;">Pengcheng Jiang</ins></strong>, <a href="https://linjc16.github.io/" rel="external nofollow noopener" target="_blank">Jiacheng Lin</a>, <a href="https://zifengwang.xyz/" rel="external nofollow noopener" target="_blank">Zifeng Wang</a>, <a href="https://www.sunlab.org/" rel="external nofollow noopener" target="_blank">Jimeng Sun</a>, and <a href="http://hanj.cs.illinois.edu/" rel="external nofollow noopener" target="_blank">Jiawei Han</a> </div> <div class="periodical"> <em>In Proc. 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/genres-naacl.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/pat-jj/GenRES" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <span id="star-count-jiang2023genres" class="github-stars"></span> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>The field of relation extraction (RE) is experiencing a notable shift towards generative relation extraction (GRE), leveraging the capabilities of large language models (LLMs). However, we discovered that traditional relation extraction (RE) metrics like precision and recall fall short in evaluating GRE methods. This shortfall arises because these metrics rely on exact matching with human-annotated reference relations, while GRE methods often produce diverse and semantically accurate relations that differ from the references. To fill this gap, we introduce \textscGenRES for a multi-dimensional assessment in terms of the topic similarity, uniqueness, granularity, factualness, and completeness of the GRE results. With \textscGenRES, we empirically identified that (1) precision/recall fails to justify the performance of GRE methods; (2) human-annotated referential relations can be incomplete; (3) prompting LLMs with a fixed set of relations or entities can cause hallucinations. Next, we conducted a human evaluation of GRE methods that shows \textscGenRES is consistent with human preferences for RE quality. Last, we made a comprehensive evaluation of fourteen leading LLMs using \textscGenRES across document, bag, and sentence level RE datasets, respectively, to set the benchmark for future research in GRE. </p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal",jiang2023medkg:"pat-jj/TextbookKG",jiang2023genres:"pat-jj/GenRES"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#ddeceb;padding:3px;color:#000;border-radius:5px;margin-left:-8px;height:auto}</style> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Under Review</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/medkg-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/medkg-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/medkg-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/medkg-1400.webp"></source> <img src="/assets/img/publication_preview/medkg.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="medkg.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="jiang2023medkg" class="col-sm-8"> <div class="title">MedKG: Empowering Medical Education with Interactive Construction and Visualization of Knowledge Graphs via Large Language Models</div> <div class="author"> <strong><ins style="color:rgb(6, 130, 213); font-weight: bold;">Pengcheng Jiang</ins></strong>, <a href="https://medium.com/@megamberlim" rel="external nofollow noopener" target="_blank">Megan Lim</a>, <a href="https://www2.osfhealthcare.org/providers/adam-cross-1601889" rel="external nofollow noopener" target="_blank">Adam Cross</a>, and <a href="https://www.sunlab.org/" rel="external nofollow noopener" target="_blank">Jimeng Sun</a> </div> <div class="periodical"> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/medgraph-jamia.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/pat-jj/TextbookKG" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <span id="star-count-jiang2023medkg" class="github-stars"></span> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>The field of relation extraction (RE) is experiencing a notable shift towards generative relation extraction (GRE), leveraging the capabilities of large language models (LLMs). However, we discovered that traditional relation extraction (RE) metrics like precision and recall fall short in evaluating GRE methods. This shortfall arises because these metrics rely on exact matching with human-annotated reference relations, while GRE methods often produce diverse and semantically accurate relations that differ from the references. To fill this gap, we introduce \textscGenRES for a multi-dimensional assessment in terms of the topic similarity, uniqueness, granularity, factualness, and completeness of the GRE results. With \textscGenRES, we empirically identified that (1) precision/recall fails to justify the performance of GRE methods; (2) human-annotated referential relations can be incomplete; (3) prompting LLMs with a fixed set of relations or entities can cause hallucinations. Next, we conducted a human evaluation of GRE methods that shows \textscGenRES is consistent with human preferences for RE quality. Last, we made a comprehensive evaluation of fourteen leading LLMs using \textscGenRES across document, bag, and sentence level RE datasets, respectively, to set the benchmark for future research in GRE. </p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal",jiang2023medkg:"pat-jj/TextbookKG",jiang2023genres:"pat-jj/GenRES"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#ddeceb;padding:3px;color:#000;border-radius:5px;margin-left:-8px;height:auto}</style> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">KDD’23</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/pyhealth-logo-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/pyhealth-logo-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/pyhealth-logo-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/pyhealth-logo-1400.webp"></source> <img src="/assets/img/publication_preview/pyhealth-logo.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="pyhealth-logo.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="10.1145/3580305.3599178" class="col-sm-8"> <div class="title">PyHealth: A Deep Learning Toolkit for Healthcare Applications</div> <div class="author"> <a href="https://ycq091044.github.io/" rel="external nofollow noopener" target="_blank">Chaoqi Yang</a>, <a href="https://zzachw.github.io/" rel="external nofollow noopener" target="_blank">Zhenbang Wu</a>, <strong><ins style="color:rgb(6, 130, 213); font-weight: bold;">Patrick Jiang</ins></strong>, <a href="https://zlin7.github.io/" rel="external nofollow noopener" target="_blank">Zhen Lin</a>, <a href="http://aboutme.vixerunt.org/" rel="external nofollow noopener" target="_blank">Junyi Gao</a>, <a href="https://www.linkedin.com/in/benjaminpdanek/" rel="external nofollow noopener" target="_blank">Benjamin Danek</a>, and <a href="https://www.sunlab.org/" rel="external nofollow noopener" target="_blank">Jimeng Sun</a> </div> <div class="periodical"> <em>In The 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/pyhealth.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/sunlabuiuc/PyHealth" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <span id="star-count-10.1145/3580305.3599178" class="github-stars"></span> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Deep learning (DL) has emerged as a promising tool in healthcare applications. However, the reproducibility of many studies in this field is limited by the lack of accessible code implementations and standard benchmarks. To address the issue, we create PyHealth, a comprehensive library to build, deploy, and validate DL pipelines for healthcare applications. PyHealth supports various data modalities, including electronic health records (EHRs), physiological signals, medical images, and clinical text. It offers various advanced DL models and maintains comprehensive medical knowledge systems. The library is designed to support both DL researchers and clinical data scientists. Upon the time of writing, PyHealth has received 633 stars, 130 forks, and 15k+ downloads in total on GitHub.This tutorial will provide an overview of PyHealth, present different modules, and showcase their functionality through hands-on demos. Participants can follow along and gain hands-on experience on the Google Colab platform during the session.</p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal",jiang2023medkg:"pat-jj/TextbookKG",jiang2023genres:"pat-jj/GenRES"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#ddeceb;padding:3px;color:#000;border-radius:5px;margin-left:-8px;height:auto}</style> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ACL’23</abbr><div class="preview-container"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 220px)" srcset="/assets/img/publication_preview/tagreal-220.webp"></source> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/tagreal-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/tagreal-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/tagreal-1400.webp"></source> <img src="/assets/img/publication_preview/tagreal.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="tagreal.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="jiang-etal-2023-text" class="col-sm-8"> <div class="title">Text Augmented Open Knowledge Graph Completion via Pre-Trained Language Models</div> <div class="author"> <strong><ins style="color:rgb(6, 130, 213); font-weight: bold;">Pengcheng Jiang</ins></strong>, <a href="https://shivamag125.github.io/" rel="external nofollow noopener" target="_blank">Shivam Agarwal</a>, <a href="https://peterjin.me/" rel="external nofollow noopener" target="_blank">Bowen Jin</a>, <a href="https://xuanwang91.github.io/" rel="external nofollow noopener" target="_blank">Xuan Wang</a>, <a href="https://www.sunlab.org/" rel="external nofollow noopener" target="_blank">Jimeng Sun</a>, and <a href="http://hanj.cs.illinois.edu/" rel="external nofollow noopener" target="_blank">Jiawei Han</a> </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: ACL 2023</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/tagreal.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/tagreal_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> <a href="https://github.com/pat-jj/TagReal" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <span id="star-count-jiang-etal-2023-text" class="github-stars"></span> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>The mission of open knowledge graph (KG) completion is to draw new findings from known facts. Existing works that augment KG completion require either (1) factual triples to enlarge the graph reasoning space or (2) manually designed prompts to extract knowledge from a pre-trained language model (PLM), exhibiting limited performance and requiring expensive efforts from experts. To this end, we propose TagReal that automatically generates quality query prompts and retrieves support information from large text corpora to probe knowledge from PLM for KG completion. The results show that TagReal achieves state-of-the-art performance on two benchmark datasets. We find that TagReal has superb performance even with limited training data, outperforming existing embedding-based, graph-based, and PLM-based methods.</p> </div> </div> </div> <script>async function getGitHubStars(t){const a=await fetch(`https://api.github.com/repos/${t}`);return(await a.json()).stargazers_count}document.addEventListener("DOMContentLoaded",()=>{const t={jiang2023graphcare:"pat-jj/GraphCare",jiang2023bilevel:"pat-jj/Gode","10.1145/3580305.3599178":"sunlabuiuc/PyHealth","jiang-etal-2023-text":"pat-jj/TagReal",jiang2023medkg:"pat-jj/TextbookKG",jiang2023genres:"pat-jj/GenRES"};Object.keys(t).forEach(async a=>{const e=t[a],n=await getGitHubStars(e);document.getElementById(`star-count-${a}`).innerText=`\u2b50\ufe0f ${n} stars`})});</script> <style>.github-stars{background-color:#ddeceb;padding:3px;color:#000;border-radius:5px;margin-left:-8px;height:auto}</style> </li> </ol> </div> <h2 style="margin-top: 80px; border-bottom: 1px solid rgb(239, 236, 236); padding-bottom: 30px;"><a href="/software/" style="color: inherit;"><strong>Software Development</strong></a></h2> <p></p> <h5> <a href="https://pyhealth.readthedocs.io/en/latest/" rel="external nofollow noopener" target="_blank">PyHealth</a> - A Deep Learning Toolkit for Healthcare</h5> <div class="software_icons"> <a href="https://pypi.org/project/pyhealth/" target="_blank" rel="noopener noreferrer"> <img src="https://img.shields.io/pypi/v/pyhealth.svg?color=brightgreen" alt="PyPI version"> </a> <a href="https://pyhealth.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer"> <img src="https://readthedocs.org/projects/pyhealth/badge/?version=latest" alt="Documentation status"> </a> <a href="https://github.com/sunlabuiuc/pyhealth/stargazers" target="_blank" rel="noopener noreferrer"> <img src="https://img.shields.io/github/stars/sunlabuiuc/pyhealth.svg" alt="GitHub stars"> </a> <a href="https://github.com/sunlabuiuc/pyhealth/network" target="_blank" rel="noopener noreferrer"> <img src="https://img.shields.io/github/forks/sunlabuiuc/pyhealth.svg?color=blue" alt="GitHub forks"> </a> <a href="https://pepy.tech/project/pyhealth" target="_blank" rel="noopener noreferrer"> <img src="https://pepy.tech/badge/pyhealth" alt="Downloads"> </a> <a href="https://pyhealth.readthedocs.io/en/latest/tutorials.html" target="_blank" rel="noopener noreferrer"> <img src="https://img.shields.io/badge/Tutorials-Google%20Colab-red" alt="Tutorials"> </a> </div> <p>Main Developers: Chaoqi Yang, Zhenbang Wu, <b>Patrick Jiang</b>, Zhen Lin, Benjamin Danek</p> <p></p> <h5> <a href="https://pat-jj.github.io/TextbookKG/">TxBKG</a> - Convert Any PDFs into Highly Interactive Knowledge Graphs!</h5> <div class="software_icons"> <a href="https://github.com/pat-jj/TextbookKG/stargazers" target="_blank" rel="noopener noreferrer"> <img src="https://img.shields.io/github/stars/pat-jj/TextbookKG.svg" alt="GitHub stars"> </a> <a href="https://github.com/pat-jj/TextbookKG/network" target="_blank" rel="noopener noreferrer"> <img src="https://img.shields.io/github/forks/pat-jj/TextbookKG?color=blue" alt="GitHub forks"> </a> </div> <p>Developer: <b>Patrick Jiang</b></p> </article> <h2 style="margin-top: 80px; border-bottom: 1px solid rgb(239, 236, 236);"></h2> <div style="display: flex; justify-content: space-between; align-items: center;"> <div style="display: flex; align-items: left;"> <a href="https://scholar.google.com/citations?hl=en&amp;user=TejDN9wAAAAJ&amp;view_op=list_works&amp;authuser=2&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank"> <img src="assets/img/google-scholar.png" style="width: 100px; height: auto;"> </a> <a href="https://github.com/pat-jj" rel="external nofollow noopener" target="_blank"> <img src="assets/img/github-icon.png" style="width: 100px; height: auto;"> </a> </div> <div id="clustrmaps-container"> <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=bWiKAH2bSIjAc4dLQ15AfqQN92lAkCtT2Bc8n2ovxw8"></script> </div> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Patrick (Pengcheng) Jiang. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>